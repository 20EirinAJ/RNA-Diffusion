{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pinellolab/DNA-Diffusion/blob/update-vqvae/notebooks/experiments/conditional_diffusion/VQ_VAE_LATENT_SPACE_WITH_METRICS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBca78a5WRED"
      },
      "source": [
        "Changes to the notebook:\n",
        "\n",
        "1. Additional metrics to validate the approach: [NOTE: some of these metrics can be repurposed for the UNET (stable diffusion part)]\n",
        "\n",
        "       a) **METRIC 1**, Recovery, defined as the percentage of fully (meaning not just parts of the sequence for)  predicted/recovered motifs from the validation set [Similiar metric is used in molecular generation as well]\n",
        "       b) **METRIC 2** Partial recovery, defined as the percentage of the motifs where we predicted atleast RECOVERY_THRESHOLD correctly, independent wether the whole sequence was predicted correctly. This RECOVER_THRESHOLD is a variable, so if we set it 50% then we count the percentage of motifs where we recovered atleast 50% of the nucleotides of that sequence.\n",
        "       b) **METRIC 3** Accuracy, defined as the percentage of nucleotides that we predicted correctly, independent wether the whole sequence was predicted correctly.\n",
        "       c) **METRIC 4**, Seperation of the latent space using low dimensional visuals, UMAP. If we can see clear seperation in lower dimensional space, that means that latent variables are not bad.\n",
        "       d) **METRIC 5** Seperation of the latent space using low dimensional visuals, non-linear projection t-SNE. If we can see clear seperation in lower dimensional space, that means that latent variables are not bad. \n",
        "       e) **METRIC 6**, Comparing different lengths of motifs (7-9-11) to a Jaspar vertrabrates DB using gimme scan.\n",
        "       f) [weak metric/proxys] **METRIC 7**, observing the composite loss and perplexity during training. Perplexity should go up and composite lose should go down. \n",
        "       \n",
        "**Perplexity**: In the context of a VQ-VAE (Vector Quantized Variational Autoencoder), perplexity is a measure of how well the model can reconstruct a given input. It is defined as the exponentiated average log-probability of the input, where the log-probability is computed using the model's decoder.\n",
        "\n",
        "Perplexity can be thought of as a measure of how \"surprised\" the model is by the input. A low perplexity indicates that the model is able to reconstruct the input well and is not surprised by it, whereas a high perplexity indicates that the model is unable to reconstruct the input well and is surprised by it.\n",
        "\n",
        "***NOTE : For all 7 Metrics (except recovery, there we rebuild little 100% of motifs, which is a good thing, we dont want to overfit) we observe favorable trends, where we can infer that the learning happens and we are finding a desired representation!***  \n",
        "   \n",
        "2. Split the test set into 3 distinct chromosomes, with expectation that different chromosomes will have different latent space. The same analysis should be repeated for different cell types.\n",
        "3. Complete pre-refactoring of the code, cleaning and writing doc strings. This is ready to be copied and merged into codebase.\n",
        "4. Adjusted the architecture for the VQ-VAE from https://github.com/zalandoresearch/pytorch-vq-vae\n",
        "5. Added theoretical explanations and motivations of different parts of the code.\n",
        "6. Reconcile different things between baseline stable diffusion nb and this one (similiar functions, variable naming, descriptions etc) such that refactoring is easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3ahQpl0WREH"
      },
      "source": [
        "This notebook is divided in following chapters:\n",
        "\n",
        "1. Utility functions\n",
        "2. Data import and preperation\n",
        "3. VQ-VAE architecture\n",
        "4. VQ-VAE training metric functions and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install einops umap-learn torchmetrics livelossplot\n",
        "!pip install gimmemotifs    #can take around 10 minutes\n",
        "!genomepy install hg38"
      ],
      "metadata": {
        "id": "8tcC3Z5NPT5M"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "from matplotlib import pyplot as plt\n",
        "import pylab\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits.mplot3d import proj3d\n",
        "%matplotlib inline\n",
        "%pylab inline\n",
        "import torch\n",
        "import copy\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "from IPython.display import display\n",
        "import torch.nn as nn\n",
        "from sklearn.manifold import TSNE\n",
        "import os; os.getpid()\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import umap.umap_ as umap\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import seaborn as sns\n",
        "\n",
        "from typing import Optional"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QbiSMtXulrW",
        "outputId": "2033596f-ac65-434c-a517-e7cf934c7656"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['pylab']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SmXhsgMMWREJ"
      },
      "outputs": [],
      "source": [
        "GLOBAL_SEED=42\n",
        "# Global seed\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "# Batch size\n",
        "\n",
        "RECOVERY_THRESHOLD = 100 \n",
        "# number of nucleotides we need to recover to classify a motif as correctly recovered\n",
        "\n",
        "num_training_updates = 15000\n",
        "#The number of training updates to perform on the model\n",
        "\n",
        "N_EPOCHS=200\n",
        "#The number of epochs to train the model for\n",
        "\n",
        "num_hiddens = 128\n",
        "#The number of hidden units in the model's hidden layers\n",
        "\n",
        "num_residual_hiddens = 32\n",
        "#The number of hidden units in the model's residual hidden layers\n",
        "\n",
        "num_residual_layers = 2\n",
        "#The number of residual layers in the model\n",
        "\n",
        "embedding_dim = 64\n",
        "#The dimensionality of the model's embeddings\n",
        "\n",
        "num_embeddings = 512\n",
        "#The number of embeddings in the model\n",
        "\n",
        "commitment_cost = 0.25\n",
        "#The commitment cost of the model, controlling the amount of information preserved in the latent space\n",
        "\n",
        "decay = 0.99\n",
        "#The decay rate of the model's moving average\n",
        "\n",
        "learning_rate = 1e-3\n",
        "# the learning rate of the net\n",
        "\n",
        "NUCLEOTIDES = {'A': 0, 'T': 1, 'G': 2, 'C': 3}\n",
        "# Lookup for the nucleotides\n",
        "\n",
        "NUCLEOTIDES_REVERSED = {0 : 'A', 1 : 'T', 2 : 'G', 3 : 'C'}\n",
        "# Reversed lookup dict is needed when reversing the one-hot encoding for the metric 6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility functions"
      ],
      "metadata": {
        "id": "nYl_ZspOrWeR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RinDsUvHWREK"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=GLOBAL_SEED) -> None:\n",
        "    \"\"\"\"\n",
        "    Seed everything.\n",
        "    \"\"\"   \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wpRdF7t6WOwZ"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode_sequences(seq: str, include_n: Optional[bool] = False) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Converts a sequence of nucleotides to a one-hot encoded tensor.\n",
        "\n",
        "    Args:\n",
        "        seq (str): The sequence of nucleotides to encode.\n",
        "        include_n (bool, optional): Whether to include 'N' nucleotides in the encoding.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The one-hot encoded tensor, with shape (sequence_length, 4).\n",
        "    \"\"\"\n",
        "    num_seq = []\n",
        "    for nucleotide in seq:\n",
        "        num_seq.append(NUCLEOTIDES[nucleotide])\n",
        "    return (F.one_hot(torch.tensor(num_seq).to(torch.int64), num_classes=len(NUCLEOTIDES))).T\n",
        "\n",
        "class PeaksDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PeaksDataset is a PyTorch dataset for representing sequences of nucleotides. It takes a DataFrame\n",
        "    as input, one-hot encodes the raw sequences, and accumulates them into a list of tensors.\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): The DataFrame containing the raw sequences.\n",
        "\n",
        "    Inputs:\n",
        "        - idx (int): The index of the sequence to return.\n",
        "\n",
        "    Outputs:\n",
        "        - x (torch.Tensor): The one-hot encoded sequence, with shape (1, sequence_length, 4).\n",
        "        - y (int): The target label, which is always set to 1 in this dataset.\n",
        "    \"\"\"\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.sequences = []\n",
        "        for curr_seq in df['raw_sequence'].tolist():\n",
        "            if len(curr_seq) != 200:\n",
        "                mid_index = len(curr_seq)//2\n",
        "                curr_seq = curr_seq[mid_index-100:mid_index+100]\n",
        "            one_hot_representation = one_hot_encode_sequences(curr_seq)\n",
        "            if one_hot_representation is not None:\n",
        "                one_hot_representation = one_hot_representation[None, :, :]\n",
        "                self.sequences.append(one_hot_representation)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.sequences)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.sequences[idx], 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data import and preperation"
      ],
      "metadata": {
        "id": "7dSGTtsZSEVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -o train_all_classifier_WM20220916.csv.gz \"https://www.dropbox.com/s/db6up7c0d4jwdp4/train_all_classifier_WM20220916.csv.gz?dl=2\"\n",
        "!gunzip train_all_classifier_WM20220916.csv.gz\n",
        "\n",
        "\n",
        "df = pd.read_csv('train_all_classifier_WM20220916.csv', delimiter='\\t')\n",
        "train_df = df[(df['seqname'] != 'chr3') & (df['seqname'] != 'chr15') & (df['seqname'] != 'chr7')]\n",
        "test_df = df[(df['seqname'] == 'chr3') | (df['seqname'] == 'chr15') | (df['seqname'] == 'chr7')]\n",
        "\n",
        "peaks_data = PeaksDataset(train_df)\n",
        "peaks_dl = DataLoader(peaks_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM0ZGauFSFVg",
        "outputId": "dbbbc699-d17d-43c0-f66b-179f3ac8981c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   146    0   146    0     0    489      0 --:--:-- --:--:-- --:--:--   488\n",
            "100   340  100   340    0     0    497      0 --:--:-- --:--:-- --:--:--   497\n",
            "100   534    0   534    0     0    479      0 --:--:--  0:00:01 --:--:--   479\n",
            "100 21.3M  100 21.3M    0     0  12.3M      0  0:00:01  0:00:01 --:--:-- 71.6M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = PeaksDataset(test_df)\n",
        "test_dl = DataLoader(test_data, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "2H9ceUu7Sed3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VQ-VAE architecture\n",
        "\n",
        "taken from # https://github.com/zalandoresearch/pytorch-vq-vae\n"
      ],
      "metadata": {
        "id": "gX9KOZbSSgUv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3kFO47UWREM"
      },
      "source": [
        "Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. \n",
        "\n",
        "In order to learn a discrete latent representation, ideas from vector quantisation (VQ) are used. Using the VQ method allows the model to circumvent issues of \"posterior collapse\" -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M8x8xI62W539"
      },
      "outputs": [],
      "source": [
        "class VectorQuantizer(nn.Module):\n",
        "    \"\"\"\n",
        "    An implementation of a vector quantizer, as described in 'Neural Discrete Representation Learning'\n",
        "    (https://arxiv.org/abs/1711.00937) by van den Oord et al.\n",
        "\n",
        "    This module can be used as a layer in a neural network to quantize the activations of the previous\n",
        "    layer. During training, the quantization loss is backpropagated through this module, and the\n",
        "    quantization vectors are learned.\n",
        "\n",
        "    Args:\n",
        "        num_embeddings (int): The number of quantization vectors, i.e. the number of possible values\n",
        "            that each activation can take.\n",
        "        embedding_dim (int): The length of each quantization vector. This should match the number of\n",
        "            channels of the activations that will be quantized.\n",
        "        commitment_cost (float): The weighting factor that determines the trade-off between the\n",
        "            quantization loss and the commitment loss. Larger values means that the quantization vectors\n",
        "            will be pushed closer to their \"optimal\" values, but at the expense of a higher quantization\n",
        "            loss.\n",
        "\n",
        "    Inputs:\n",
        "        - inputs (torch.Tensor): The activations to be quantized, with shape (batch_size, channels,\n",
        "            height, width).\n",
        "\n",
        "    Outputs:\n",
        "        - loss (torch.Tensor): The quantization loss, a scalar value.\n",
        "        - quantized (torch.Tensor): The quantized activations, with the same shape as the inputs.\n",
        "        - perplexity (torch.Tensor): The perplexity of the encodings, a scalar value.\n",
        "        - encodings (torch.Tensor): The encodings for the inputs, with shape (batch_size,\n",
        "            num_embeddings).\n",
        "        - encoding_indices (torch.Tensor): The indices of the encodings in the quantization vector\n",
        "            space, with shape (batch_size, 1).\n",
        "    \"\"\"\n",
        "    def __init__(self, num_embeddings: int, embedding_dim: int, commitment_cost: float) -> None:\n",
        "        super(VectorQuantizer, self).__init__()\n",
        "        \n",
        "        self._embedding_dim = embedding_dim\n",
        "        self._num_embeddings = num_embeddings\n",
        "        \n",
        "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
        "        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)\n",
        "        self._commitment_cost = commitment_cost\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor):\n",
        "        # convert inputs from BCHW -> BHWC\n",
        "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
        "        input_shape = inputs.shape\n",
        "        \n",
        "        # Flatten input\n",
        "        flat_input = inputs.view(-1, self._embedding_dim)\n",
        "        \n",
        "        # Calculate distances\n",
        "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
        "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
        "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
        "            \n",
        "        # Encoding\n",
        "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
        "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
        "        encodings.scatter_(1, encoding_indices, 1)\n",
        "        \n",
        "        # Quantize and unflatten\n",
        "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
        "        \n",
        "        # Loss\n",
        "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
        "        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n",
        "        loss = q_latent_loss + self._commitment_cost * e_latent_loss\n",
        "        \n",
        "        quantized = inputs + (quantized - inputs).detach()\n",
        "        avg_probs = torch.mean(encodings, dim=0)\n",
        "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
        "        \n",
        "        # convert quantized from BHWC -> BCHW\n",
        "        return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings, encoding_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bZjdv6CHW8LN"
      },
      "outputs": [],
      "source": [
        "class VectorQuantizerEMA(nn.Module):\n",
        "    \"\"\"\n",
        "    An implementation of a vector quantizer, with an exponential moving average (EMA) update rule\n",
        "    for the quantization vectors. This module can be used as a layer in a neural network to quantize\n",
        "    the activations of the previous layer. During training, the quantization loss is backpropagated\n",
        "    through this module, and the quantization vectors are learned using the EMA update rule.\n",
        "\n",
        "    Args:\n",
        "        num_embeddings (int): The number of quantization vectors, i.e. the number of possible values\n",
        "            that each activation can take.\n",
        "        embedding_dim (int): The length of each quantization vector. This should match the number of\n",
        "            channels of the activations that will be quantized.\n",
        "        commitment_cost (float): The weighting factor that determines the trade-off between the\n",
        "            quantization loss and the commitment loss. Larger values means that the quantization vectors\n",
        "            will be pushed closer to their \"optimal\" values, but at the expense of a higher quantization\n",
        "            loss.\n",
        "        decay (float): The decay rate for the exponential moving average.\n",
        "        epsilon (float): A small constant value added to the cluster size to avoid division by zero.\n",
        "\n",
        "    Inputs:\n",
        "        - inputs (torch.Tensor): The activations to be quantized, with shape (batch_size, channels,\n",
        "            height, width).\n",
        "\n",
        "    Outputs:\n",
        "        - loss (torch.Tensor): The quantization loss, a scalar value.\n",
        "        - quantized (torch.Tensor): The quantized activations, with the same shape as the inputs.\n",
        "        - perplexity (torch.Tensor): The perplexity of the encodings, a scalar value.\n",
        "        - encodings (torch.Tensor): The encodings for the inputs, with shape (batch_size,\n",
        "            num_embeddings).\n",
        "        - encoding_indices (torch.Tensor): The indices of the encodings in the quantization vector\n",
        "            space, with shape (batch_size, 1).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, num_embeddings: int, embedding_dim: int, commitment_cost: float, decay: float, epsilon: float=1e-5):\n",
        "        super(VectorQuantizerEMA, self).__init__()\n",
        "        \n",
        "        self._embedding_dim = embedding_dim\n",
        "        self._num_embeddings = num_embeddings\n",
        "        \n",
        "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
        "        self._embedding.weight.data.normal_()\n",
        "        self._commitment_cost = commitment_cost\n",
        "        \n",
        "        self.register_buffer('_ema_cluster_size', torch.zeros(num_embeddings))\n",
        "        self._ema_w = nn.Parameter(torch.Tensor(num_embeddings, self._embedding_dim))\n",
        "        self._ema_w.data.normal_()\n",
        "        \n",
        "        self._decay = decay\n",
        "        self._epsilon = epsilon\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor):\n",
        "        # convert inputs from BCHW -> BHWC\n",
        "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
        "        input_shape = inputs.shape\n",
        "        \n",
        "        # Flatten input\n",
        "        flat_input = inputs.view(-1, self._embedding_dim)\n",
        "        \n",
        "        # Calculate distances\n",
        "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
        "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
        "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
        "            \n",
        "        # Encoding\n",
        "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
        "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
        "        encodings.scatter_(1, encoding_indices, 1)\n",
        "        \n",
        "        # Quantize and unflatten\n",
        "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
        "        \n",
        "        # Use EMA to update the embedding vectors\n",
        "        if self.training:\n",
        "            self._ema_cluster_size = self._ema_cluster_size * self._decay + \\\n",
        "                                     (1 - self._decay) * torch.sum(encodings, 0)\n",
        "            \n",
        "            # Laplace smoothing of the cluster size\n",
        "            n = torch.sum(self._ema_cluster_size.data)\n",
        "            self._ema_cluster_size = (\n",
        "                (self._ema_cluster_size + self._epsilon)\n",
        "                / (n + self._num_embeddings * self._epsilon) * n)\n",
        "            \n",
        "            dw = torch.matmul(encodings.t(), flat_input)\n",
        "            self._ema_w = nn.Parameter(self._ema_w * self._decay + (1 - self._decay) * dw)\n",
        "            \n",
        "            self._embedding.weight = nn.Parameter(self._ema_w / self._ema_cluster_size.unsqueeze(1))\n",
        "        \n",
        "        # Loss\n",
        "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
        "        loss = self._commitment_cost * e_latent_loss\n",
        "        \n",
        "        # Straight Through Estimator\n",
        "        quantized = inputs + (quantized - inputs).detach()\n",
        "        avg_probs = torch.mean(encodings, dim=0)\n",
        "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
        "        \n",
        "        # convert quantized from BHWC -> BCHW\n",
        "        return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings, encoding_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4fT8YNJaW9jj"
      },
      "outputs": [],
      "source": [
        "class Residual(nn.Module):\n",
        "    \"\"\"\n",
        "    A residual block, as described in the paper 'Deep Residual Learning for Image Recognition'\n",
        "    (https://arxiv.org/abs/1512.03385) by He et al. This block consists of two convolutional layers\n",
        "    with ReLU activation, followed by a residual connection that adds the input to the output of the\n",
        "    block.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): The number of channels in the input.\n",
        "        num_hiddens (int): The number of channels in the output.\n",
        "        num_residual_hiddens (int): The number of channels in the intermediate outputs of the block.\n",
        "\n",
        "    Inputs:\n",
        "        - x (torch.Tensor): The input tensor with shape (batch_size, in_channels, height, width).\n",
        "\n",
        "    Outputs:\n",
        "        - y (torch.Tensor): The output tensor with shape (batch_size, num_hiddens, height, width).\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, num_hiddens: int, num_residual_hiddens: int) -> None:\n",
        "        super(Residual, self).__init__()\n",
        "        self._block = nn.Sequential(\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(in_channels=in_channels,\n",
        "                      out_channels=num_residual_hiddens,\n",
        "                      kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(in_channels=num_residual_hiddens,\n",
        "                      out_channels=num_hiddens,\n",
        "                      kernel_size=1, stride=1, bias=False)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return x + self._block(x)\n",
        "\n",
        "\n",
        "class ResidualStack(nn.Module):\n",
        "    \"\"\"\n",
        "    A stack of residual blocks, as described in the paper 'Deep Residual Learning for Image\n",
        "    Recognition' (https://arxiv.org/abs/1512.03385) by He et al. This stack consists of a specified\n",
        "    number of residual blocks, each with the same number of channels in the input and output, and the\n",
        "    same number of channels in the intermediate outputs.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): The number of channels in the input to the stack.\n",
        "        num_hiddens (int): The number of channels in the output from the stack.\n",
        "        num_residual_layers (int): The number of residual blocks in the stack.\n",
        "        num_residual_hiddens (int): The number of channels in the intermediate outputs of each block.\n",
        "\n",
        "    Inputs:\n",
        "        - x (torch.Tensor): The input tensor with shape (batch_size, in_channels, height, width).\n",
        "\n",
        "    Outputs:\n",
        "        - y (torch.Tensor): The output tensor with shape (batch_size, num_hiddens, height, width).\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, num_hiddens: int, num_residual_layers: int, num_residual_hiddens: int) -> None:\n",
        "        super(ResidualStack, self).__init__()\n",
        "        self._num_residual_layers = num_residual_layers\n",
        "        self._layers = nn.ModuleList([Residual(in_channels, num_hiddens, num_residual_hiddens)\n",
        "                             for _ in range(self._num_residual_layers)])\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        for i in range(self._num_residual_layers):\n",
        "            x = self._layers[i](x)\n",
        "        return F.relu(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eCL5uXjdW-4A"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels: int, num_hiddens: int, num_residual_layers: int, num_residual_hiddens: int) -> None:\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self._conv_1 = nn.Conv2d(in_channels=in_channels,\n",
        "                                 out_channels=num_hiddens//2,\n",
        "                                 kernel_size=(4, 10),\n",
        "                                 stride=2, padding=(1, 4))\n",
        "        self._conv_2 = nn.Conv2d(in_channels=num_hiddens//2,\n",
        "                                 out_channels=num_hiddens,\n",
        "                                 kernel_size=4,\n",
        "                                 stride=2, padding=1)\n",
        "        self._conv_3 = nn.Conv2d(in_channels=num_hiddens,\n",
        "                                 out_channels=num_hiddens,\n",
        "                                 kernel_size=3,\n",
        "                                 stride=1, padding=1)\n",
        "        self._residual_stack = ResidualStack(in_channels=num_hiddens,\n",
        "                                             num_hiddens=num_hiddens,\n",
        "                                             num_residual_layers=num_residual_layers,\n",
        "                                             num_residual_hiddens=num_residual_hiddens)\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
        "        x = self._conv_1(inputs)\n",
        "        x = F.relu(x)\n",
        "        x = self._conv_2(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self._conv_3(x)\n",
        "        return self._residual_stack(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A4NGCBnMXAR0"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder is a PyTorch module that takes the quantized latent representations and decodes them\n",
        "    into the original input space. It consists of a sequence of convolutional and deconvolutional layers\n",
        "    followed by a residual stack.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): The number of channels in the input tensor.\n",
        "        num_hiddens (int): The number of channels in the hidden layers of the decoder.\n",
        "        num_residual_layers (int): The number of residual layers in the decoder.\n",
        "        num_residual_hiddens (int): The number of channels in the intermediate outputs of the residual\n",
        "            blocks in the decoder.\n",
        "\n",
        "    Inputs:\n",
        "        - inputs (torch.Tensor): The input tensor with shape (B, in_channels, H, W), where B is the\n",
        "            batch size, in_channels is the number of channels in the input, and H and W are the height\n",
        "            and width of the tensor.\n",
        "\n",
        "    Outputs:\n",
        "        - x (torch.Tensor): The output tensor with shape (B, 1, H', W'), where H' and W' are the height\n",
        "            and width of the decoded tensor, respectively.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, num_hiddens: int, num_residual_layers: int, num_residual_hiddens: int) -> None:\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self._conv_1 = nn.Conv2d(in_channels=in_channels,\n",
        "                                 out_channels=num_hiddens,\n",
        "                                 kernel_size=3, \n",
        "                                 stride=1, padding=1)\n",
        "        \n",
        "        self._residual_stack = ResidualStack(in_channels=num_hiddens,\n",
        "                                             num_hiddens=num_hiddens,\n",
        "                                             num_residual_layers=num_residual_layers,\n",
        "                                             num_residual_hiddens=num_residual_hiddens)\n",
        "        \n",
        "        self._conv_trans_1 = nn.ConvTranspose2d(in_channels=num_hiddens, \n",
        "                                                out_channels=num_hiddens//2,\n",
        "                                                kernel_size=4, \n",
        "                                                stride=2, padding=1)\n",
        "        \n",
        "        self._conv_trans_2 = nn.ConvTranspose2d(in_channels=num_hiddens//2, \n",
        "                                                out_channels=1,\n",
        "                                                kernel_size=(2, 12), \n",
        "                                                stride=2, padding=(0, 5))\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
        "        x = self._conv_1(inputs)\n",
        "        \n",
        "        x = self._residual_stack(x)\n",
        "        \n",
        "        x = self._conv_trans_1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        return self._conv_trans_2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aLmbEXplXhmU"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    \"\"\"\n",
        "    Model is a PyTorch module for the VQ-VAE model described in the paper 'Neural Discrete\n",
        "    Representation Learning' (https://arxiv.org/abs/1711.00937) by van den Oord et al. It consists of\n",
        "    an encoder, a vector quantization module, and a decoder. The vector quantization module can be\n",
        "    either a VectorQuantizer or a VectorQuantizerEMA, depending on the value of the decay argument.\n",
        "\n",
        "    Args:\n",
        "        num_hiddens (int): The number of channels in the hidden layers of the encoder and decoder.\n",
        "        num_residual_layers (int): The number of residual layers in the encoder and decoder.\n",
        "        num_residual_hiddens (int): The number of channels in the intermediate outputs of the residual\n",
        "            blocks in the encoder and decoder.\n",
        "        num_embeddings (int): The number of embeddings in the vector quantization module.\n",
        "        embedding_dim (int): The dimension of the embedding vectors in the vector quantization module.\n",
        "        commitment_cost (float): The commitment cost, which controls the balance between reconstruction\n",
        "            loss and the commitment to the learned codebook.\n",
        "        decay (float, optional): The decay rate of the moving average used in the vector quantization\n",
        "            module. If 0, then the vector quantization module is not EMA-enabled.\n",
        "\n",
        "    Inputs:\n",
        "        - x (torch.Tensor): The input tensor\n",
        "    \"\"\"\n",
        "    def __init__(self, num_hiddens: int, num_residual_layers: int, num_residual_hiddens: int, \n",
        "                 num_embeddings: int, embedding_dim: int, commitment_cost: float, decay: Optional[float]=0) -> None:\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self._encoder = Encoder(1, num_hiddens,\n",
        "                                num_residual_layers, \n",
        "                                num_residual_hiddens)\n",
        "        self._pre_vq_conv = nn.Conv2d(in_channels=num_hiddens, \n",
        "                                      out_channels=embedding_dim,\n",
        "                                      kernel_size=1, \n",
        "                                      stride=1)\n",
        "        if decay > 0.0:\n",
        "            self._vq_vae = VectorQuantizerEMA(num_embeddings, embedding_dim, \n",
        "                                              commitment_cost, decay)\n",
        "        else:\n",
        "            self._vq_vae = VectorQuantizer(num_embeddings, embedding_dim,\n",
        "                                           commitment_cost)\n",
        "        self._decoder = Decoder(embedding_dim,\n",
        "                                num_hiddens, \n",
        "                                num_residual_layers, \n",
        "                                num_residual_hiddens)\n",
        "\n",
        "    def forward(self, x:torch.Tensor):\n",
        "        z = self._encoder(x)\n",
        "        z = self._pre_vq_conv(z)\n",
        "        loss, quantized, perplexity, _, encoding_index = self._vq_vae(z)\n",
        "        x_recon = self._decoder(quantized)\n",
        "        return loss, x_recon, perplexity, quantized, encoding_index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VQ-VAE training metric functions and evaluation"
      ],
      "metadata": {
        "id": "gibUcNi9SrtD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7AKmwb59WRES"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "model = Model(num_hiddens, num_residual_layers, num_residual_hiddens,\n",
        "              num_embeddings, embedding_dim, \n",
        "              commitment_cost, decay)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5xE1a2ewZ7A0",
        "outputId": "22007c2b-6e59-4130-c678-e52b652ec432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 iterations\n",
            "loss: 0.188\n",
            "perplexity: 1.000\n",
            "\n",
            "200 iterations\n",
            "loss: 0.197\n",
            "perplexity: 1.000\n",
            "\n",
            "300 iterations\n",
            "loss: 0.198\n",
            "perplexity: 1.000\n",
            "\n",
            "400 iterations\n",
            "loss: 0.199\n",
            "perplexity: 1.000\n",
            "\n",
            "500 iterations\n",
            "loss: 0.202\n",
            "perplexity: 1.000\n",
            "\n",
            "600 iterations\n",
            "loss: 0.204\n",
            "perplexity: 1.000\n",
            "\n",
            "700 iterations\n",
            "loss: 0.205\n",
            "perplexity: 1.000\n",
            "\n",
            "800 iterations\n",
            "loss: 0.176\n",
            "perplexity: 2.015\n",
            "\n",
            "900 iterations\n",
            "loss: 0.142\n",
            "perplexity: 13.907\n",
            "\n",
            "1000 iterations\n",
            "loss: 0.112\n",
            "perplexity: 76.372\n",
            "\n",
            "100 iterations\n",
            "loss: 0.091\n",
            "perplexity: 172.928\n",
            "\n",
            "200 iterations\n",
            "loss: 0.075\n",
            "perplexity: 210.090\n",
            "\n",
            "300 iterations\n",
            "loss: 0.066\n",
            "perplexity: 218.639\n",
            "\n",
            "400 iterations\n",
            "loss: 0.059\n",
            "perplexity: 225.343\n",
            "\n",
            "500 iterations\n",
            "loss: 0.055\n",
            "perplexity: 228.754\n",
            "\n",
            "600 iterations\n",
            "loss: 0.051\n",
            "perplexity: 230.365\n",
            "\n",
            "700 iterations\n",
            "loss: 0.048\n",
            "perplexity: 233.452\n",
            "\n",
            "800 iterations\n",
            "loss: 0.045\n",
            "perplexity: 236.132\n",
            "\n",
            "900 iterations\n",
            "loss: 0.045\n",
            "perplexity: 237.592\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-cd881ce86080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mrecon_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecon_error\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvq_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# with adjusted kernel size to capture motifs\n",
        "train_res_recon_error = []\n",
        "train_res_perplexity = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    for i, (data, _) in enumerate(peaks_dl):\n",
        "        data = data.float()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        vq_loss, data_recon, perplexity, hidden_quantized, encoding_index = model(data)\n",
        "        recon_error = F.mse_loss(data_recon, data) / 1\n",
        "        loss = recon_error + vq_loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_res_recon_error.append(recon_error.item())\n",
        "        train_res_perplexity.append(perplexity.item())\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('%d iterations' % (i+1))\n",
        "            print('loss: %.3f' % loss)\n",
        "            print('perplexity: %.3f' % np.mean(train_res_perplexity[-100:]))\n",
        "            print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_CzG-zvWRES"
      },
      "source": [
        "Quantitative evaluation of the latent space. Visually we can also see up until the 3rd dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlJSeiZmWRES"
      },
      "source": [
        "a) **METRIC 1**, **METRIC 2** and  **METRIC 3**(recovery, partial recover and accuracy):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables to store the number of correct predictions and the total number of predictions made by the model\n",
        "\n",
        "# this variable counts the number of nucleotides that were correct across ALL of the motifs\n",
        "num_correct_predictions = 0\n",
        "# this variable only counts if we have predicted the whole motif correctly (all of the nucleotides given)\n",
        "num_correct_predictions_full = 0\n",
        "# this variable only counts if we have predicted the  motif correctly above the threshold RECOVERY_THRESHOLD (i.e. more nucleotides then specified by the threshold)\n",
        "num_correct_predictions_partially = 0\n",
        "# this variable holds all of the nucleotides\n",
        "num_total_predictions = 0\n",
        "# this variable holds all of the full motifs predictions\n",
        "num_total_predictions_full = 0\n",
        "# this variable holds all of the (one-hot-encoded) predictions\n",
        "whole_predictions_full = []\n",
        "\n",
        "\n",
        "# Iterate over the original validation data and unused variable in the test_dl variable\n",
        "for original_valid_data, _ in test_dl:\n",
        "    # Convert the original validation data to a float tensor\n",
        "    original_valid_data = original_valid_data.float()\n",
        "\n",
        "    # Apply the encoder and pre-VQ-convolution layers of the model to the original validation data\n",
        "    vq_output = model._pre_vq_conv(model._encoder(original_valid_data))\n",
        "\n",
        "    # Apply the VQ-VAE layers of the model to the VQ output and extract the quantized data\n",
        "    _, quantized_valid_data, _, _, _ = model._vq_vae(vq_output)\n",
        "\n",
        "    # Apply the decoder of the model to the quantized data to obtain the reconstructed data\n",
        "    reconstructed_valid_data = model._decoder(quantized_valid_data)\n",
        "\n",
        "    # Extract the ground truth labels from the original validation data\n",
        "    ground_truth = torch.argmax(original_valid_data, dim=2)\n",
        "\n",
        "    # Extract the predicted labels from the reconstructed data\n",
        "    prediction = torch.argmax(reconstructed_valid_data, dim=2)\n",
        "    whole_predictions_full.append(prediction)\n",
        "\n",
        "    # Iterate over the items in the batch of data\n",
        "    for i in range(original_valid_data.shape[0]):\n",
        "        # Increment the number of correct predictions if the predicted label for this item matches the ground truth label\n",
        "        num_correct_predictions += int((prediction[i][0] == ground_truth[i][0]).sum())\n",
        "        if int((prediction[i][0] == ground_truth[i][0]).sum())==200:\n",
        "          num_correct_predictions_full += 1\n",
        "        elif int((prediction[i][0] == ground_truth[i][0]).sum())>RECOVERY_THRESHOLD:\n",
        "          num_correct_predictions_partially += 1\n",
        "\n",
        "        # Increment the total number of predictions\n",
        "        num_total_predictions += 200\n",
        "        # Increment the total full number of predictions\n",
        "        num_total_predictions_full += 1\n"
      ],
      "metadata": {
        "id": "ZQ-d_1oFW5gP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy:"
      ],
      "metadata": {
        "id": "tosqJ7RKzAU4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Jy8rja-hbpWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a463d628-20f0-4e42-f9d1-5a9b146335cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9430208996215292"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "percentage_correct_predictions_nucleotides = num_correct_predictions/num_total_predictions\n",
        "percentage_correct_predictions_nucleotides"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recovery: "
      ],
      "metadata": {
        "id": "HGfaZ67ZzBos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "percentage_correct_predictions_full = num_correct_predictions_full/num_total_predictions_full\n",
        "percentage_correct_predictions_full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUb3vAauyc0R",
        "outputId": "8c5ce8ac-b264-4db7-b723-44b47f9a2ded"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Partial recovery (the constant RECOVERY_THRESHOLD number of nucleotides we need to recover to classify a motif as correctly recovered)"
      ],
      "metadata": {
        "id": "u1xSzk9SzBnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "percentage_correct_predictions_partially = num_correct_predictions_partially/num_total_predictions_full\n",
        "percentage_correct_predictions_partially"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYu1cBgQzNGQ",
        "outputId": "38338d02-47a7-4873-a972-cfc9d502967d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSaihQDjWREU"
      },
      "source": [
        "c) **METRIC 4**, Seperation of the latent space with visuals. We know that per Cell Type there should be different distributions if learnt properly. Used three different methods here. First T-SNE visualisation, PCA to relatively rank the latent space and then plot them using UMAPs. PCA explains more then 0.96 of the variance with only 10 latent features. 0.5 of the variance is explained with 3.\n",
        "\n",
        "\n",
        "HOW TO INTERPRET THIS?\n",
        "\n",
        "If we plot in all 2 dimensions, and we see very little clusters (1 being the worst) while using the 1-2-3 most important (orthogonal and kernel projected) features, then we know that the algorithm most likely learned little"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "u776jqsAWREU"
      },
      "outputs": [],
      "source": [
        "def draw_umap(n_neighbors=15, min_dist=0.1, n_components=2, metric='euclidean', title=''):\n",
        "    \"\"\"\n",
        "    This functions depicts the seperation for 3 possible dimensions.\n",
        "    \"\"\"\n",
        "    \n",
        "    fit = umap.UMAP(\n",
        "        n_neighbors=n_neighbors,\n",
        "        min_dist=min_dist,\n",
        "        n_components=n_components,\n",
        "        metric=metric\n",
        "    )\n",
        "    u = fit.fit_transform(model._vq_vae._embedding.weight.data.cpu())\n",
        "    fig = plt.figure()\n",
        "    if n_components == 1:\n",
        "        ax = fig.add_subplot(111)\n",
        "        ax.scatter(u[:,0], range(len(u)))\n",
        "    if n_components == 2:\n",
        "        ax = fig.add_subplot(111)\n",
        "        ax.scatter(u[:,0], u[:,1])\n",
        "    if n_components == 3:\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        ax.scatter(u[:,0], u[:,1], u[:,2], s=100)\n",
        "    plt.title(title, fontsize=18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ndBbNF0pWREU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "79208f01-193a-495b-e65c-40af7c8bde6d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "draw_umap(n_components=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "aaDQeLFEWREU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "80d2ac68-d395-44ab-f6a7-f69ef1779ffd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "draw_umap(n_components=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rYQxU5hWREU"
      },
      "source": [
        "d) **METRIC 5** Seperation of the latent space using low dimensional visuals, non-linear projection t-SNE. If we can see clear seperation in lower dimensional space, that means that latent variables are not bad. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWs5swoZWREV"
      },
      "source": [
        "Now we will apply t-SNE (t-Distributed Stochastic Neighbor Embedding) is nonlinear dimensionality reduction technique in which interrelated high dimensional data (usually hundreds or thousands of variables) is mapped into low-dimensional data (like 2 or 3 variables) while preserving the significant structure (relationship among the data points in different variables) of original high dimensional data.\n",
        "\n",
        "Note, we applied UMAP on the PCA projected space. For t-SNE we apply it on the raw data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2Q-1u-rCWREV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "81f5e7b2-e971-4c16-aced-e9d498c47cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  warnings.warn(\n",
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "tsne = TSNE(n_components=2, random_state=0).fit_transform(model._vq_vae._embedding.weight.data.cpu())\n",
        "x, y = list(zip(*tsne))\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.scatter(x, y)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY5Z6eMAWREV"
      },
      "source": [
        "e) **METRIC 6**, Comparing different lengths of motifs (7-9-11) to a standard DB using TomTom tool https://meme-suite.org/meme/tools/tomtom\n",
        "\n",
        "However, there TomTom is only available through R, hence I used gimmemotifs: https://gimmemotifs.readthedocs.io/en/master/reference.html#gimme-scan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiAxnO_BWREV"
      },
      "source": [
        "First we have to convert the one hot encoded sequences to the original raw motif sequence.\n",
        "\n",
        "**NOTE**\n",
        "\n",
        "Change the following variable to control the motif length.\n",
        "\n",
        "Be carefull, the smaller the number that we set, the more memory will be consumed and it will run longer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MOTIF_LENGTH=200"
      ],
      "metadata": {
        "id": "e2dGLZ0PMnGW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we reverse the one hot encoding of the predictions from VQ-VAE"
      ],
      "metadata": {
        "id": "Jt2Msox5Rlno"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9FRhujDVWREV"
      },
      "outputs": [],
      "source": [
        "df_raw_sequences=[]\n",
        "# iterate over all sequences\n",
        "for batch_prediction in whole_predictions_full:\n",
        "    for prediction in batch_prediction:\n",
        "      motif_holder=[]\n",
        "      for nucleotide in prediction[0]:\n",
        "        motif_holder.append(NUCLEOTIDES_REVERSED[nucleotide.item()])\n",
        "\n",
        "      df_raw_sequences.append(''.join(motif_holder))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccj70c-zWREV"
      },
      "source": [
        "Now we need to convert this list to either FASTA or bed and feed it to the gimme scan command in order to check occurances of motifs in jaspar vertebrates database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_w6H35D_WREV"
      },
      "outputs": [],
      "source": [
        "def save_motifs_to_fasta(motifs, fasta_file):\n",
        "    # Open the FASTA file in write mode\n",
        "    with open(fasta_file, 'w') as f:\n",
        "        # Iterate over the motifs\n",
        "        for i, motif in enumerate(motifs):\n",
        "          for j in range(200//MOTIF_LENGTH):\n",
        "            # Write the motif to the file\n",
        "            f.write(f'>motif_{i+1}_{j+1}\\n{motif[j*MOTIF_LENGTH:(j+1)*MOTIF_LENGTH]}\\n')\n",
        "\n",
        "save_motifs_to_fasta(df_raw_sequences, \"recoded_motifs_seqs.fasta\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hgokDO9tWREW"
      },
      "outputs": [],
      "source": [
        "def motifs_from_fasta(fasta):\n",
        "    \"\"\"\n",
        "    Extract motifs from fasta.\n",
        "    \"\"\"\n",
        "    print ('Computing Motifs....')\n",
        "    !gimme scan $fasta -p  JASPAR2020_vertebrates -g hg38 > train_results_motifs.bed\n",
        "    df_results_seq_guime = pd.read_csv('train_results_motifs.bed', sep='\\t', skiprows=5, header=None)\n",
        "    return df_results_seq_guime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df_results_seq_guime=motifs_from_fasta('recoded_motifs_seqs.fasta')"
      ],
      "metadata": {
        "id": "z9q5oNoWPCx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d06af6-9ceb-4884-8d62-8eb9adf2f2e3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing Motifs....\n",
            "2022-12-14 14:30:49,383 - INFO - No config found.\n",
            "2022-12-14 14:30:49,383 - INFO - Creating new config.\n",
            "2022-12-14 14:30:49,386 - INFO - Using included version of MDmodule.\n",
            "2022-12-14 14:30:49,401 - WARNING - MEME not found. To include it you will have to install it.\n",
            "2022-12-14 14:30:49,414 - WARNING - MEMEW not found. To include it you will have to install it.\n",
            "2022-12-14 14:30:49,427 - WARNING - DREME not found. To include it you will have to install it.\n",
            "2022-12-14 14:30:49,440 - WARNING - Weeder not found. To include it you will have to install it.\n",
            "2022-12-14 14:30:49,454 - WARNING - GADEM not found. To include it you will have to install it.\n",
            "2022-12-14 14:30:49,454 - INFO - Using included version of MotifSampler.\n",
            "2022-12-14 14:30:49,467 - WARNING - Trawler not found. To include it you will have to install it.\n",
            "2022-12-14 14:30:49,467 - INFO - Using included version of Improbizer.\n",
            "2022-12-14 14:30:49,467 - INFO - Using included version of BioProspector.\n",
            "2022-12-14 14:30:49,467 - INFO - Using included version of Posmo.\n",
            "2022-12-14 14:30:49,467 - INFO - Using included version of ChIPMunk.\n",
            "2022-12-14 14:30:49,467 - INFO - Using included version of AMD.\n",
            "2022-12-14 14:30:49,467 - INFO - Using included version of HMS.\n",
            "2022-12-14 14:30:49,481 - WARNING - Homer not found. To include it you will have to install it.\n",
            "2022-12-14 14:30:49,494 - WARNING - XXmotif not found. To include it you will have to install it.\n",
            "2022-12-14 14:30:49,507 - WARNING - ProSampler not found. To include it you will have to install it.\n",
            "2022-12-14 14:30:49,507 - WARNING - Yamda not in config\n",
            "2022-12-14 14:30:49,520 - WARNING - DiNAMO not found. To include it you will have to install it.\n",
            "2022-12-14 14:30:49,534 - WARNING - RPMCMC not found. To include it you will have to install it.\n",
            "2022-12-14 14:30:49,534 - INFO - Configuration file: /root/.config/gimmemotifs/gimmemotifs.cfg\n",
            "2022-12-14 14:30:52,955 - INFO - determining FPR-based threshold\n",
            "scanning: 100% 29857/29857 [03:54<00:00, 127.51 sequences/s] \n",
            "CPU times: user 3 s, sys: 356 ms, total: 3.35 s\n",
            "Wall time: 5min 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_results_seq_guime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lBlB5ynPG2PU",
        "outputId": "8915d1ba-44e3-44b6-e5ce-9b8f98726f23"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    0        1             2    3    4          5  6  7  \\\n",
              "0           motif_1_1  pfmscan  misc_feature  133  144  10.743772  -  .   \n",
              "1           motif_1_1  pfmscan  misc_feature   77   89   9.295637  -  .   \n",
              "2           motif_1_1  pfmscan  misc_feature   77   89   9.161552  -  .   \n",
              "3           motif_1_1  pfmscan  misc_feature   78   86   8.922553  +  .   \n",
              "4           motif_1_1  pfmscan  misc_feature  124  135  10.158267  -  .   \n",
              "...               ...      ...           ...  ...  ...        ... .. ..   \n",
              "335890  motif_29857_1  pfmscan  misc_feature   44   54   9.495406  -  .   \n",
              "335891  motif_29857_1  pfmscan  misc_feature   44   54   9.689605  -  .   \n",
              "335892  motif_29857_1  pfmscan  misc_feature   44   54   9.218449  -  .   \n",
              "335893  motif_29857_1  pfmscan  misc_feature   27   43   7.443503  -  .   \n",
              "335894  motif_29857_1  pfmscan  misc_feature   48   61  10.590401  -  .   \n",
              "\n",
              "                                                        8  \n",
              "0       motif_name \"MA0465.2_CDX2\" ; motif_instance \"T...  \n",
              "1       motif_name \"MA0114.4_HNF4A\" ; motif_instance \"...  \n",
              "2       motif_name \"MA0484.2_HNF4G\" ; motif_instance \"...  \n",
              "3       motif_name \"MA1534.1_NR1I3\" ; motif_instance \"...  \n",
              "4       motif_name \"MA0070.1_PBX1\" ; motif_instance \"T...  \n",
              "...                                                   ...  \n",
              "335890  motif_name \"MA1648.1_TCF12(var.2)\" ; motif_ins...  \n",
              "335891  motif_name \"MA0522.3_TCF3\" ; motif_instance \"G...  \n",
              "335892  motif_name \"MA0103.3_ZEB1\" ; motif_instance \"G...  \n",
              "335893  motif_name \"MA1597.1_ZNF528\" ; motif_instance ...  \n",
              "335894  motif_name \"UN0219.1_ZNF75A\" ; motif_instance ...  \n",
              "\n",
              "[335895 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fbaaf97-0b60-47e1-b1d4-bf0fb7f9a615\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>motif_1_1</td>\n",
              "      <td>pfmscan</td>\n",
              "      <td>misc_feature</td>\n",
              "      <td>133</td>\n",
              "      <td>144</td>\n",
              "      <td>10.743772</td>\n",
              "      <td>-</td>\n",
              "      <td>.</td>\n",
              "      <td>motif_name \"MA0465.2_CDX2\" ; motif_instance \"T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>motif_1_1</td>\n",
              "      <td>pfmscan</td>\n",
              "      <td>misc_feature</td>\n",
              "      <td>77</td>\n",
              "      <td>89</td>\n",
              "      <td>9.295637</td>\n",
              "      <td>-</td>\n",
              "      <td>.</td>\n",
              "      <td>motif_name \"MA0114.4_HNF4A\" ; motif_instance \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>motif_1_1</td>\n",
              "      <td>pfmscan</td>\n",
              "      <td>misc_feature</td>\n",
              "      <td>77</td>\n",
              "      <td>89</td>\n",
              "      <td>9.161552</td>\n",
              "      <td>-</td>\n",
              "      <td>.</td>\n",
              "      <td>motif_name \"MA0484.2_HNF4G\" ; motif_instance \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>motif_1_1</td>\n",
              "      <td>pfmscan</td>\n",
              "      <td>misc_feature</td>\n",
              "      <td>78</td>\n",
              "      <td>86</td>\n",
              "      <td>8.922553</td>\n",
              "      <td>+</td>\n",
              "      <td>.</td>\n",
              "      <td>motif_name \"MA1534.1_NR1I3\" ; motif_instance \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>motif_1_1</td>\n",
              "      <td>pfmscan</td>\n",
              "      <td>misc_feature</td>\n",
              "      <td>124</td>\n",
              "      <td>135</td>\n",
              "      <td>10.158267</td>\n",
              "      <td>-</td>\n",
              "      <td>.</td>\n",
              "      <td>motif_name \"MA0070.1_PBX1\" ; motif_instance \"T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335890</th>\n",
              "      <td>motif_29857_1</td>\n",
              "      <td>pfmscan</td>\n",
              "      <td>misc_feature</td>\n",
              "      <td>44</td>\n",
              "      <td>54</td>\n",
              "      <td>9.495406</td>\n",
              "      <td>-</td>\n",
              "      <td>.</td>\n",
              "      <td>motif_name \"MA1648.1_TCF12(var.2)\" ; motif_ins...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335891</th>\n",
              "      <td>motif_29857_1</td>\n",
              "      <td>pfmscan</td>\n",
              "      <td>misc_feature</td>\n",
              "      <td>44</td>\n",
              "      <td>54</td>\n",
              "      <td>9.689605</td>\n",
              "      <td>-</td>\n",
              "      <td>.</td>\n",
              "      <td>motif_name \"MA0522.3_TCF3\" ; motif_instance \"G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335892</th>\n",
              "      <td>motif_29857_1</td>\n",
              "      <td>pfmscan</td>\n",
              "      <td>misc_feature</td>\n",
              "      <td>44</td>\n",
              "      <td>54</td>\n",
              "      <td>9.218449</td>\n",
              "      <td>-</td>\n",
              "      <td>.</td>\n",
              "      <td>motif_name \"MA0103.3_ZEB1\" ; motif_instance \"G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335893</th>\n",
              "      <td>motif_29857_1</td>\n",
              "      <td>pfmscan</td>\n",
              "      <td>misc_feature</td>\n",
              "      <td>27</td>\n",
              "      <td>43</td>\n",
              "      <td>7.443503</td>\n",
              "      <td>-</td>\n",
              "      <td>.</td>\n",
              "      <td>motif_name \"MA1597.1_ZNF528\" ; motif_instance ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335894</th>\n",
              "      <td>motif_29857_1</td>\n",
              "      <td>pfmscan</td>\n",
              "      <td>misc_feature</td>\n",
              "      <td>48</td>\n",
              "      <td>61</td>\n",
              "      <td>10.590401</td>\n",
              "      <td>-</td>\n",
              "      <td>.</td>\n",
              "      <td>motif_name \"UN0219.1_ZNF75A\" ; motif_instance ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>335895 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fbaaf97-0b60-47e1-b1d4-bf0fb7f9a615')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2fbaaf97-0b60-47e1-b1d4-bf0fb7f9a615 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2fbaaf97-0b60-47e1-b1d4-bf0fb7f9a615');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_MOTIF_OCCURANCES_TO_PLOT=20"
      ],
      "metadata": {
        "id": "x1qqachM_4gf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(y='motifs',data=df_results_seq_guime, order=pd.value_counts(df_results_seq_guime['motifs']).iloc[:N_MOTIF_OCCURANCES_TO_PLOT].index)"
      ],
      "metadata": {
        "id": "SVz5KhZ14EZf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}